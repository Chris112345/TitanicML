{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'Q', 'S', 'S', 'S',\n",
       "       'C', 'S', 'Q', 'S', 'C', 'C', 'Q', 'S', 'C', 'S', 'C', 'S', 'S',\n",
       "       'C', 'S', 'S', 'C', 'C', 'Q', 'S', 'Q', 'Q', 'C', 'S', 'S', 'S',\n",
       "       'C', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'C', nan, 'S', 'S', 'C',\n",
       "       'C', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'C', 'C', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'C', 'S', 'S', 'C', 'S', 'Q',\n",
       "       'S', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'Q', 'S', 'C', 'S',\n",
       "       'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'C', 'S', 'S',\n",
       "       'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'S', 'S', 'S', 'S', 'Q', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'C', 'Q', 'S', 'Q', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'Q', 'C', 'S', 'S', 'S', 'S', 'Q', 'C', 'S', 'S', 'C', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'C', 'Q', 'S', 'S', 'C', 'Q', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'C', 'S', 'C', 'S',\n",
       "       'Q', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'C', 'Q', 'S', 'S', 'S', 'Q', 'S', 'Q', 'S', 'S', 'S', 'S', 'C',\n",
       "       'S', 'S', 'S', 'Q', 'S', 'C', 'C', 'S', 'S', 'C', 'C', 'S', 'S',\n",
       "       'C', 'Q', 'Q', 'S', 'Q', 'S', 'S', 'C', 'C', 'C', 'C', 'C', 'C',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'Q', 'S', 'S',\n",
       "       'C', 'S', 'S', 'S', 'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'C', 'S', 'C', 'S', 'S', 'S', 'Q', 'Q', 'S', 'C', 'C', 'S',\n",
       "       'Q', 'S', 'C', 'C', 'Q', 'C', 'C', 'S', 'S', 'C', 'S', 'C', 'S',\n",
       "       'C', 'C', 'S', 'C', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'C',\n",
       "       'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'Q', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'Q',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'C', 'S',\n",
       "       'C', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'Q', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'C',\n",
       "       'S', 'C', 'C', 'S', 'S', 'S', 'S', 'Q', 'Q', 'S', 'S', 'C', 'S',\n",
       "       'S', 'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'S', 'Q', 'S', 'S',\n",
       "       'S', 'S', 'C', 'C', 'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'C', 'C',\n",
       "       'C', 'S', 'S', 'S', 'C', 'S', 'C', 'S', 'S', 'S', 'S', 'C', 'S',\n",
       "       'S', 'C', 'S', 'S', 'C', 'S', 'Q', 'C', 'S', 'S', 'C', 'C', 'S',\n",
       "       'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'Q', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'S', 'C', 'C',\n",
       "       'S', 'S', 'C', 'S', 'S', 'S', 'C', 'S', 'Q', 'S', 'S', 'S', 'S',\n",
       "       'C', 'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'S', 'S',\n",
       "       'S', 'Q', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'C', 'S',\n",
       "       'S', 'S', 'Q', 'S', 'S', 'Q', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'C', 'S', 'C', 'S', 'S',\n",
       "       'S', 'S', 'S', 'Q', 'Q', 'S', 'S', 'Q', 'S', 'C', 'S', 'C', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'C', 'Q', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'S', 'C', 'S', 'C', 'S', 'S', 'S', 'Q', 'C', 'S', 'C', 'S',\n",
       "       'C', 'Q', 'S', 'S', 'S', 'S', 'S', 'C', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'C', 'S', 'Q', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'Q',\n",
       "       'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S',\n",
       "       'S', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'C',\n",
       "       'Q', 'Q', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'Q', 'S', 'Q', 'S',\n",
       "       'C', 'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'C', 'Q', 'S', 'S',\n",
       "       'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'C', 'S', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'Q', 'S', 'C', 'Q', nan, 'C', 'S',\n",
       "       'C', 'S', 'S', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'C', 'C', 'S',\n",
       "       'S', 'S', 'C', 'S', 'C', 'S', 'S', 'C', 'S', 'S', 'S', 'S', 'S',\n",
       "       'C', 'C', 'S', 'S', 'S', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'S', 'S', 'C', 'C', 'S', 'S', 'S', 'C', 'S', 'S', 'S', 'S',\n",
       "       'S', 'Q', 'S', 'S', 'S', 'C', 'Q'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = pd.read_csv(\"../Data/train.csv\")\n",
    "trainingData.hist(bins = 10)\n",
    "trainingData[\"Embarked\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Analog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgeBins = pd.IntervalIndex.from_tuples([(0,15),(15,30),(30,45),(45,60),(60,75),(75,90),(90,105),(105,120)])\n",
    "TicketBins = pd.IntervalIndex.from_tuples([(0,50000), (50000,100000), (100000,150000),(150000,200000),(200000, 250000), (250000, 300000), (300000, 350000)])\n",
    "CostBins = pd.IntervalIndex.from_tuples([(-1, 50),(50,100), (100,150), (150, 200), (200, 250), (250, 300), (300,350), (350,400), (400, 450), (450, 500), (500, 550)])\n",
    "\n",
    "trainingData[\"AgeGroup\"] = pd.cut(trainingData['Age'], bins=AgeBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "trainingData['TicketGroup'] = pd.cut(pd.to_numeric(trainingData['Ticket'], errors=\"coerce\"), bins=TicketBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "trainingData['CostGroup'] = pd.cut(trainingData['Fare'], bins=CostBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "trainingData['Embarked'] = trainingData['Embarked'].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvTrain1 = trainingData[0:(4*trainingData[\"Survived\"].count()//5)]\n",
    "cvTest1 = trainingData[(4*trainingData[\"Survived\"].count()//5):]\n",
    "\n",
    "cvTrain2 = trainingData[0:(3*trainingData[\"Survived\"].count()//5)].append(trainingData[(4*trainingData[\"Survived\"].count()//5):])\n",
    "cvTest2 = trainingData[(3*trainingData[\"Survived\"].count()//5):(4*trainingData[\"Survived\"].count()//5)]\n",
    "\n",
    "cvTrain3 = trainingData[0:(2*trainingData[\"Survived\"].count()//5)].append(trainingData[(3*trainingData[\"Survived\"].count()//5):])\n",
    "cvTest3 = trainingData[(2*trainingData[\"Survived\"].count()//5):(3*trainingData[\"Survived\"].count()//5)]\n",
    "\n",
    "cvTrain4 = trainingData[0:trainingData[\"Survived\"].count()//5].append(trainingData[(2*trainingData[\"Survived\"].count()//5):])\n",
    "cvTest4 = trainingData[trainingData[\"Survived\"].count()//5:(2*trainingData[\"Survived\"].count()//5)]\n",
    "\n",
    "cvTrain5 = trainingData[trainingData[\"Survived\"].count()//5:]\n",
    "cvTest5 = trainingData[0:trainingData[\"Survived\"].count()//5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    \n",
    "    def __init__(self, feature, children):\n",
    "        self.feature = feature\n",
    "        self.children = children\n",
    "        \n",
    "    def getFeature(self):\n",
    "        return self.feature\n",
    "    \n",
    "    def search(self,datapoint):\n",
    "        if self.children is None:\n",
    "            return self.getFeature()\n",
    "        point = datapoint.get(self.feature)\n",
    "        for child in self.children:\n",
    "            if child[0] == point:\n",
    "                return child[1].search(datapoint)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Structure Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf1 = Tree(0, None)\n",
    "leaf2 = Tree(1, None)\n",
    "leaf3 = Tree(1, None)\n",
    "\n",
    "branch = Tree(\"test2\", [[\"b1\",leaf1], [\"b2\",leaf2]])\n",
    "root = Tree(\"test1\", [[\"a1\",branch], [\"a2\",leaf3]])\n",
    "\n",
    "EXdata = pd.Series(data=[\"a1\",\"b1\"],index=[\"test1\",\"test2\"])\n",
    "\n",
    "assert 0 == root.search(EXdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(dataSet):\n",
    "    result1 = dataSet[dataSet['Survived'] == 1].size/dataSet.size\n",
    "    if result1 == 0 or result1 == 1:\n",
    "        return 0\n",
    "    result1 = result1*np.log2(result1)\n",
    "    result2 = dataSet[dataSet['Survived'] == 0].size/dataSet.size\n",
    "    result2 =  result2*np.log2(result2)\n",
    "    return -1* (result1 + result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InformationGain(dataSet, feature):\n",
    "    \n",
    "    totalE = Entropy(dataSet)\n",
    "    sumE = 0\n",
    "    \n",
    "    values, counts = np.unique(dataSet[feature], return_counts = True)\n",
    "    for val in values:\n",
    "        sumE += (dataSet[dataSet[feature] == val].size)/dataSet.size*Entropy(dataSet[dataSet[feature] == val])\n",
    "    return totalE - sumE\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildTree(depth,features,dataset):\n",
    "    \n",
    "    values, counts = np.unique(dataset[\"Survived\"], return_counts = True)\n",
    "    if counts[0] == dataset.size:\n",
    "        return Tree(values[0], None)\n",
    "    \n",
    "        \n",
    "    \n",
    "    best = None\n",
    "    bestIG = 0\n",
    "    for feat in features:\n",
    "        IG = InformationGain(dataset, feat)\n",
    "        if best == None or bestIG < IG:\n",
    "            best = feat\n",
    "            bestIG = IG\n",
    "    \n",
    "    \n",
    "    children = []\n",
    "    if depth == 1 or len(features) == 1:\n",
    "        for val in np.unique(dataset[best]):\n",
    "            children.append([val,Tree(dataset[dataset[best] == val].mode().loc[0, \"Survived\"], None)])\n",
    "    else:\n",
    "        subset = features.copy()\n",
    "        subset.remove(best)\n",
    "        for val in np.unique(dataset[best]):\n",
    "            \n",
    "            children.append([val, BuildTree(depth-1, subset, dataset[dataset[best] == val])])\n",
    "                            \n",
    "    return Tree(best, children)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Tree Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTree = BuildTree(3, [\"AgeGroup\", \"CostGroup\", \"TicketGroup\"], trainingData)\n",
    "testTree.search(trainingData.loc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataSet, tree):\n",
    "    \n",
    "    correct = 0\n",
    "    for ID in dataSet[\"PassengerId\"]:\n",
    "        dataPoint = dataSet.loc[ID-1]\n",
    "        if dataPoint[\"Survived\"] == tree.search(dataPoint):\n",
    "            correct+=1\n",
    "        \n",
    "    return correct/dataSet[\"PassengerId\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [0.7988826815642458, 0.7359550561797753, 0.7865168539325843, 0.797752808988764, 0.8146067415730337], 2: [0.7988826815642458, 0.7303370786516854, 0.7921348314606742, 0.7640449438202247, 0.7584269662921348], 3: [0.8659217877094972, 0.7865168539325843, 0.7808988764044944, 0.7808988764044944, 0.7865168539325843], 4: [0.8435754189944135, 0.7752808988764045, 0.7921348314606742, 0.7696629213483146, 0.7865168539325843], 5: [0.7821229050279329, 0.7528089887640449, 0.7247191011235955, 0.7191011235955056, 0.6797752808988764]}\n"
     ]
    }
   ],
   "source": [
    "depths = [1,2,3,4,5]\n",
    "feats = [\"Pclass\", \"Sex\", \"AgeGroup\", \"SibSp\", \"Parch\",\"TicketGroup\", \"CostGroup\", \"Embarked\"]\n",
    "results = {}\n",
    "\n",
    "for depth in depths:\n",
    "    accuracies = []\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain1)\n",
    "    accuracies.append(accuracy(cvTest1, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain2)\n",
    "    accuracies.append(accuracy(cvTest2, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain3)\n",
    "    accuracies.append(accuracy(cvTest3, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain4)\n",
    "    accuracies.append(accuracy(cvTest4, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain5)\n",
    "    accuracies.append(accuracy(cvTest5, tree))\n",
    "    \n",
    "    results[depth] = accuracies\n",
    "    \n",
    "print(results)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1\n",
      "0.7867428284476806\n",
      "\n",
      "Depth: 2\n",
      "0.768765300357793\n",
      "\n",
      "Depth: 3\n",
      "0.8001506496767309\n",
      "\n",
      "Depth: 4\n",
      "0.7934341849224782\n",
      "\n",
      "Depth: 5\n",
      "0.7317054798819911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(\"Depth: \" + str(result))\n",
    "    print(str(sum(results[result])/len(results[result])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Accuracy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:  0.8327721661054994\n"
     ]
    }
   ],
   "source": [
    "learnedTree = BuildTree(3,feats,trainingData)\n",
    "\n",
    "print(\"Training Set Accuracy: \", accuracy(trainingData,learnedTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

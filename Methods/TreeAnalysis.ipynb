{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x10829490>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x118946D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x118B7750>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x118DA830>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x118F9910>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1191A9F0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1193AB50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1195A610>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1195ABB0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = pd.read_csv(\"../Data/train.csv\")\n",
    "trainingData.hist(bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Analog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgeBins = pd.IntervalIndex.from_tuples([(0,15),(15,30),(30,45),(45,60),(60,75),(75,90),(90,105),(105,120)])\n",
    "TicketBins = pd.IntervalIndex.from_tuples([(0,50000), (50000,100000), (100000,150000),(150000,200000),(200000, 250000), (250000, 300000), (300000, 350000)])\n",
    "CostBins = pd.IntervalIndex.from_tuples([(-1, 50),(50,100), (100,150), (150, 200), (200, 250), (250, 300), (300,350), (350,400), (400, 450), (450, 500), (500, 550)])\n",
    "\n",
    "trainingData[\"AgeGroup\"] = pd.cut(trainingData['Age'], bins=AgeBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "trainingData['TicketGroup'] = pd.cut(pd.to_numeric(trainingData['Ticket'], errors=\"coerce\"), bins=TicketBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "trainingData['CostGroup'] = pd.cut(trainingData['Fare'], bins=CostBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "trainingData['Embarked'] = trainingData['Embarked'].fillna(\"S\")\n",
    "\n",
    "def nameClass(row):\n",
    "    if (re.search(\"Mr\\.\",row[\"Name\"])):\n",
    "        return(\"Mr.\")\n",
    "    elif (re.search(\"Mrs\\.\",row[\"Name\"])):\n",
    "        return(\"Mrs.\")\n",
    "    elif (re.search(\"Miss\\.\",row[\"Name\"])):\n",
    "        return(\"Miss.\")\n",
    "    else:\n",
    "        return(\"No Title\")\n",
    "        \n",
    "trainingData[\"Title\"] = trainingData.apply(lambda row: nameClass(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvTrain1 = trainingData[0:(4*trainingData[\"Survived\"].count()//5)]\n",
    "cvTest1 = trainingData[(4*trainingData[\"Survived\"].count()//5):]\n",
    "\n",
    "cvTrain2 = trainingData[0:(3*trainingData[\"Survived\"].count()//5)].append(trainingData[(4*trainingData[\"Survived\"].count()//5):])\n",
    "cvTest2 = trainingData[(3*trainingData[\"Survived\"].count()//5):(4*trainingData[\"Survived\"].count()//5)]\n",
    "\n",
    "cvTrain3 = trainingData[0:(2*trainingData[\"Survived\"].count()//5)].append(trainingData[(3*trainingData[\"Survived\"].count()//5):])\n",
    "cvTest3 = trainingData[(2*trainingData[\"Survived\"].count()//5):(3*trainingData[\"Survived\"].count()//5)]\n",
    "\n",
    "cvTrain4 = trainingData[0:trainingData[\"Survived\"].count()//5].append(trainingData[(2*trainingData[\"Survived\"].count()//5):])\n",
    "cvTest4 = trainingData[trainingData[\"Survived\"].count()//5:(2*trainingData[\"Survived\"].count()//5)]\n",
    "\n",
    "cvTrain5 = trainingData[trainingData[\"Survived\"].count()//5:]\n",
    "cvTest5 = trainingData[0:trainingData[\"Survived\"].count()//5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    \n",
    "    def __init__(self, feature, children):\n",
    "        self.feature = feature\n",
    "        self.children = children\n",
    "        \n",
    "    def getFeature(self):\n",
    "        return self.feature\n",
    "    \n",
    "    def search(self,datapoint):\n",
    "        if self.children is None:\n",
    "            return self.getFeature()\n",
    "        point = datapoint.get(self.feature)\n",
    "        for child in self.children:\n",
    "            if child[0] == point:\n",
    "                return child[1].search(datapoint)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Structure Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf1 = Tree(0, None)\n",
    "leaf2 = Tree(1, None)\n",
    "leaf3 = Tree(1, None)\n",
    "\n",
    "branch = Tree(\"test2\", [[\"b1\",leaf1], [\"b2\",leaf2]])\n",
    "root = Tree(\"test1\", [[\"a1\",branch], [\"a2\",leaf3]])\n",
    "\n",
    "EXdata = pd.Series(data=[\"a1\",\"b1\"],index=[\"test1\",\"test2\"])\n",
    "\n",
    "assert 0 == root.search(EXdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(dataSet):\n",
    "    result1 = dataSet[dataSet['Survived'] == 1].size/dataSet.size\n",
    "    if result1 == 0 or result1 == 1:\n",
    "        return 0\n",
    "    result1 = result1*np.log2(result1)\n",
    "    result2 = dataSet[dataSet['Survived'] == 0].size/dataSet.size\n",
    "    result2 =  result2*np.log2(result2)\n",
    "    return -1* (result1 + result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InformationGain(dataSet, feature):\n",
    "    \n",
    "    totalE = Entropy(dataSet)\n",
    "    sumE = 0\n",
    "    \n",
    "    values, counts = np.unique(dataSet[feature], return_counts = True)\n",
    "    for val in values:\n",
    "        sumE += (dataSet[dataSet[feature] == val].size)/dataSet.size*Entropy(dataSet[dataSet[feature] == val])\n",
    "    return totalE - sumE\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildTree(depth,features,dataset):\n",
    "    \n",
    "    values, counts = np.unique(dataset[\"Survived\"], return_counts = True)\n",
    "    if counts[0] == dataset.size or depth == 0:\n",
    "        return Tree(values[0], None)\n",
    "    \n",
    "        \n",
    "    \n",
    "    best = None\n",
    "    bestIG = 0\n",
    "    for feat in features:\n",
    "        IG = InformationGain(dataset, feat)\n",
    "        if best == None or bestIG < IG:\n",
    "            best = feat\n",
    "            bestIG = IG\n",
    "    \n",
    "    \n",
    "    children = []\n",
    "    if depth == 1 or len(features) == 1:\n",
    "        for val in np.unique(dataset[best]):\n",
    "            children.append([val,Tree(dataset[dataset[best] == val].mode().loc[0, \"Survived\"], None)])\n",
    "    else:\n",
    "        subset = features.copy()\n",
    "        subset.remove(best)\n",
    "        for val in np.unique(dataset[best]):\n",
    "            \n",
    "            children.append([val, BuildTree(depth-1, subset, dataset[dataset[best] == val])])\n",
    "                            \n",
    "    return Tree(best, children)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Tree Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTree = BuildTree(3, [\"AgeGroup\", \"CostGroup\", \"TicketGroup\"], trainingData)\n",
    "testTree.search(trainingData.loc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataSet, tree):\n",
    "    \n",
    "    correct = 0\n",
    "    for ID in dataSet[\"PassengerId\"]:\n",
    "        dataPoint = dataSet.loc[ID-1]\n",
    "        if dataPoint[\"Survived\"] == tree.search(dataPoint):\n",
    "            correct+=1\n",
    "        \n",
    "    return correct/dataSet[\"PassengerId\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1,2,3,4,5]\n",
    "feats = [\"Pclass\", \"Sex\", \"AgeGroup\", \"SibSp\", \"Parch\",\"TicketGroup\", \"CostGroup\", \"Embarked\", \"Title\"]\n",
    "results = {}\n",
    "\n",
    "for depth in depths:\n",
    "    accuracies = []\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain1)\n",
    "    accuracies.append(accuracy(cvTest1, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain2)\n",
    "    accuracies.append(accuracy(cvTest2, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain3)\n",
    "    accuracies.append(accuracy(cvTest3, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain4)\n",
    "    accuracies.append(accuracy(cvTest4, tree))\n",
    "    \n",
    "    tree = BuildTree(depth,feats,cvTrain5)\n",
    "    accuracies.append(accuracy(cvTest5, tree))\n",
    "    \n",
    "    results[depth] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1\n",
      "0.7721423639445106\n",
      "\n",
      "Depth: 2\n",
      "0.775500596321637\n",
      "\n",
      "Depth: 3\n",
      "0.7732659594501287\n",
      "\n",
      "Depth: 4\n",
      "0.7765865294080723\n",
      "\n",
      "Depth: 5\n",
      "0.7530286862092775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(\"Depth: \" + str(result))\n",
    "    print(str(sum(results[result])/len(results[result])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Accuracy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:  0.8316498316498316\n"
     ]
    }
   ],
   "source": [
    "learnedTree = BuildTree(3,feats,trainingData)\n",
    "\n",
    "print(\"Training Set Accuracy: \", accuracy(trainingData,learnedTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"../Data/train.csv\")\n",
    "\n",
    "testData[\"AgeGroup\"] = pd.cut(testData['Age'], bins=AgeBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "testData['TicketGroup'] = pd.cut(pd.to_numeric(testData['Ticket'], errors=\"coerce\"), bins=TicketBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "testData['CostGroup'] = pd.cut(testData['Fare'], bins=CostBins).cat.add_categories(pd.Interval(-2,-1)).fillna(pd.Interval(-2,-1))\n",
    "testData['Embarked'] = testData['Embarked'].fillna(\"S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ID3_Disc_Tree.csv', mode='w', newline='') as treedone:\n",
    "    treedone = csv.writer(treedone)\n",
    "    treedone.writerow(['PassengerId', 'Survived'])\n",
    "    \n",
    "    for index in range(418):\n",
    "        label = learnedTree.search(testData.loc[index])\n",
    "        if label == 0:\n",
    "            treedone.writerow([index+892, 1])\n",
    "        else:\n",
    "            treedone.writerow([index+892, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
